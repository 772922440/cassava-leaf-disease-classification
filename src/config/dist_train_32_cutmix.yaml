# split train.csv
k_folds: 5
data_base_path: "../data2"

backbone: tf_efficientnet_b4
optimizer: SGD
momentum: 0.9
batch_size: 32
accumulated_gradient: 1
epochs: 15
weight_decay: 2e-4
max_grad_norm: 10
print_freq: 100
model_suffix: '_cutmix'

transform: "strong_fix2"
p: 0.9 # for transform
criterion: BiTemperedLoss
t1: 0.8
t2: 1.2
# criterion: LabelSmoothing
smoothing: 0.6

# scheduler: GradualWarmupScheduler
# total_epoch: 5
# after_scheduler: CosineAnnealingLR
scheduler: CosineAnnealingLR
lr: 1e-2
min_lr: 1e-3

amp: False
apex: False
DDP: True
norm_confusion_matrix: True
num_workers: 8

cutmix: True
cutmix_prob: 0.3