{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T04:05:24.327476Z",
     "iopub.status.busy": "2021-01-28T04:05:24.326767Z",
     "iopub.status.idle": "2021-01-28T04:05:28.073164Z",
     "shell.execute_reply": "2021-01-28T04:05:28.072139Z"
    },
    "papermill": {
     "duration": 3.759837,
     "end_time": "2021-01-28T04:05:28.073319",
     "exception": false,
     "start_time": "2021-01-28T04:05:24.313482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms \n",
    "import torch\n",
    "\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os \n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from PIL import Image, ImageOps\n",
    "import sys\n",
    "sys.path.append('../input/pytorchimagemodels/pytorch-image-models-master')\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T04:05:28.094395Z",
     "iopub.status.busy": "2021-01-28T04:05:28.093833Z",
     "iopub.status.idle": "2021-01-28T04:05:28.097546Z",
     "shell.execute_reply": "2021-01-28T04:05:28.097099Z"
    },
    "papermill": {
     "duration": 0.018859,
     "end_time": "2021-01-28T04:05:28.097650",
     "exception": false,
     "start_time": "2021-01-28T04:05:28.078791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimmBackbone(nn.Module):\n",
    "    def __init__(self, model_name= 'mobilenetv3_large_100', pretrained=False, target_size = 5):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        # n_features = self.model.fc.in_features\n",
    "        self.model.reset_classifier(target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class EnsembleWeight(nn.Module):\n",
    "    def __init__(self, model_size = 5, target_size = 5):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.tensor([[0.6528, 0.7624, 0.8109, 0.7850, 0.8738],\n",
    "            [0.0281, 0.0388, 0.0609, 0.0287, 0.0526],\n",
    "            [0.0225, 0.0260, 0.0194, 0.0242, 0.0147],\n",
    "            [0.2687, 0.1444, 0.0838, 0.1314, 0.0436],\n",
    "            [0.0279, 0.0285, 0.0250, 0.0307, 0.0153]]))\n",
    "\n",
    "    def forward(self, x): \n",
    "        # b, model, cls\n",
    "        x = torch.sum(self.w * x, dim=1)\n",
    "        x /= x.sum(dim=-1, keepdim=True).detach()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T04:05:28.117415Z",
     "iopub.status.busy": "2021-01-28T04:05:28.115802Z",
     "iopub.status.idle": "2021-01-28T04:05:28.118036Z",
     "shell.execute_reply": "2021-01-28T04:05:28.118457Z"
    },
    "papermill": {
     "duration": 0.015672,
     "end_time": "2021-01-28T04:05:28.118557",
     "exception": false,
     "start_time": "2021-01-28T04:05:28.102885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transform = A.Compose([\n",
    "            A.Resize(512,512),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "            ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{TEST_PATH}/{file_name}'\n",
    "\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        return image.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T04:05:28.140237Z",
     "iopub.status.busy": "2021-01-28T04:05:28.138493Z",
     "iopub.status.idle": "2021-01-28T04:05:28.140919Z",
     "shell.execute_reply": "2021-01-28T04:05:28.141337Z"
    },
    "papermill": {
     "duration": 0.017956,
     "end_time": "2021-01-28T04:05:28.141435",
     "exception": false,
     "start_time": "2021-01-28T04:05:28.123479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model_list, test_loader, device):\n",
    "#     tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        \n",
    "        print(model_list)\n",
    "        # load models\n",
    "        for backbone, filenames in model_list.items():\n",
    "            backbone, model_base_path = backbone.split(';')\n",
    "            model = TimmBackbone(model_name=backbone).to(device=device)\n",
    "            model.eval()\n",
    "\n",
    "            for filename in filenames:\n",
    "                model_path = os.path.join(model_base_path, filename)\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(dim=-1).to('cpu'))\n",
    "\n",
    "        # simple mean weights\n",
    "        if METHOD == \"mean\":\n",
    "            avg_preds = torch.mean(torch.stack(avg_preds), dim=0)\n",
    "        else:\n",
    "            avg_preds = WEIGHT_MODEL(torch.stack(avg_preds, dim=1).to(device)).to('cpu')\n",
    "        probs.append(avg_preds)\n",
    "\n",
    "    probs = torch.cat(probs, dim=0)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T04:05:28.501551Z",
     "iopub.status.busy": "2021-01-28T04:05:28.500858Z",
     "iopub.status.idle": "2021-01-28T04:05:32.759480Z",
     "shell.execute_reply": "2021-01-28T04:05:32.758958Z"
    },
    "papermill": {
     "duration": 4.613132,
     "end_time": "2021-01-28T04:05:32.759594",
     "exception": false,
     "start_time": "2021-01-28T04:05:28.146462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_PATH = '../input/cassava-leaf-disease-classification/test_images'\n",
    "OUTPUT_DIR = './'\n",
    "METHOD = \"mean\"\n",
    "ENSEMBLE_MODELS ={\n",
    "#     \"mobilenetv3_large_100;../input/mobilenetv3-large-100/mobilenetv3_large_100\"\n",
    "#     : ['fold0_best.pth', 'fold1_best.pth', 'fold2_best.pth', 'fold3_best.pth', 'fold4_best.pth'],\n",
    "#     \"tf_efficientnet_b3;../input/efficientnet-b3-test1/models/tf_efficientnet_b3\" :\n",
    "#     ['fold0_best.pth', 'fold1_best.pth', 'fold2_best.pth', 'fold3_best.pth', 'fold4_best.pth']\n",
    "        \"tf_efficientnet_b4;../input/efficientnet-b4-test1/tf_efficientnet_b4\" :\n",
    "      ['fold0_best.pth', 'fold1_best.pth', 'fold2_best.pth', 'fold3_best.pth', 'fold4_best.pth']\n",
    "}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_size= sum(len(ENSEMBLE_MODELS[b]) for b in ENSEMBLE_MODELS)\n",
    "WEIGHT_MODEL = EnsembleWeight(model_size, 5).to(DEVICE)\n",
    "\n",
    "test = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\n",
    "test.head()\n",
    "test_dataset = TestDataset(test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T04:05:32.777829Z",
     "iopub.status.busy": "2021-01-28T04:05:32.777294Z",
     "iopub.status.idle": "2021-01-28T04:05:40.410975Z",
     "shell.execute_reply": "2021-01-28T04:05:40.411388Z"
    },
    "papermill": {
     "duration": 7.64616,
     "end_time": "2021-01-28T04:05:40.411527",
     "exception": false,
     "start_time": "2021-01-28T04:05:32.765367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tf_efficientnet_b4;../input/efficientnet-b4-test1/tf_efficientnet_b4': ['fold0_best.pth', 'fold1_best.pth', 'fold2_best.pth', 'fold3_best.pth', 'fold4_best.pth']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = inference(ENSEMBLE_MODELS, test_loader, DEVICE)\n",
    "test['label'] = predictions.argmax(-1).numpy()\n",
    "test[['image_id', 'label']].to_csv(OUTPUT_DIR + 'submission.csv', index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.005863,
     "end_time": "2021-01-28T04:05:40.423766",
     "exception": false,
     "start_time": "2021-01-28T04:05:40.417903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 20.344091,
   "end_time": "2021-01-28T04:05:40.842330",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-28T04:05:20.498239",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
