{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms \n",
    "import torch\n",
    "\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os \n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from PIL import Image, ImageOps\n",
    "import sys\n",
    "sys.path.append('../input/pytorchimagemodels/pytorch-image-models-master')\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "sys.path.append('../input/toolbelt/pytorch-toolbelt-develop')\n",
    "from pytorch_toolbelt.inference import tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimmBackbone(nn.Module):\n",
    "    def __init__(self, model_name= 'mobilenetv3_large_100', pretrained=False, target_size = 5):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        # n_features = self.model.fc.in_features\n",
    "        self.model.reset_classifier(target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class EnsembleWeight(nn.Module):\n",
    "    def __init__(self, model_size = 5, target_size = 5):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.tensor([[0.6528, 0.7624, 0.8109, 0.7850, 0.8738],\n",
    "            [0.0281, 0.0388, 0.0609, 0.0287, 0.0526],\n",
    "            [0.0225, 0.0260, 0.0194, 0.0242, 0.0147],\n",
    "            [0.2687, 0.1444, 0.0838, 0.1314, 0.0436],\n",
    "            [0.0279, 0.0285, 0.0250, 0.0307, 0.0153]]))\n",
    "\n",
    "    def forward(self, x): \n",
    "        # b, model, cls\n",
    "        x = torch.sum(self.w * x, dim=1)\n",
    "        x /= x.sum(dim=-1, keepdim=True).detach()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transform = A.Compose([\n",
    "            A.Resize(IMAGE_SIZE,IMAGE_SIZE),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "            ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{TEST_PATH}/{file_name}'\n",
    "\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        return image.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model_list, test_loader, device):\n",
    "#     tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        \n",
    "        print(model_list)\n",
    "        # load models\n",
    "        for backbone, filenames in model_list.items():\n",
    "            backbone, model_base_path = backbone.split(';')\n",
    "            model = TimmBackbone(model_name=backbone).to(device=device)\n",
    "            model.eval()\n",
    "            \n",
    "\n",
    "            for filename in filenames:\n",
    "                model_path = os.path.join(model_base_path, filename)\n",
    "                model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if TTA:\n",
    "                        y_preds = tta.TTAWrapper(model, tta.d4_image2label)(images)\n",
    "                    else:\n",
    "                        y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(dim=-1).to('cpu'))\n",
    "\n",
    "        # simple mean weights\n",
    "        if METHOD == \"mean\":\n",
    "            avg_preds = torch.mean(torch.stack(avg_preds), dim=0)\n",
    "        else:\n",
    "            avg_preds = WEIGHT_MODEL(torch.stack(avg_preds, dim=1).to(device)).to('cpu')\n",
    "        probs.append(avg_preds)\n",
    "\n",
    "    probs = torch.cat(probs, dim=0)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = '../input/cassava-leaf-disease-classification/test_images'\n",
    "OUTPUT_DIR = './'\n",
    "METHOD = \"mean\"\n",
    "ENSEMBLE_MODELS ={\n",
    "#     \"mobilenetv3_large_100;../input/mobilenetv3-large-100/mobilenetv3_large_100\"\n",
    "#     : ['fold0_best.pth', 'fold1_best.pth', 'fold2_best.pth', 'fold3_best.pth', 'fold4_best.pth'],\n",
    "    \"tf_efficientnet_b3;../input/eb3-test2-label-smooth-strong-fix-09/tf_efficientnet_b3\" :\n",
    "    ['fold0_best.pth', 'fold1_best.pth', 'fold2_best.pth', 'fold3_best.pth', 'fold4_best.pth']\n",
    "}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_size= sum(len(ENSEMBLE_MODELS[b]) for b in ENSEMBLE_MODELS)\n",
    "WEIGHT_MODEL = EnsembleWeight(model_size, 5).to(DEVICE)\n",
    "TTA = False\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "test = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\n",
    "test.head()\n",
    "test_dataset = TestDataset(test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = inference(ENSEMBLE_MODELS, test_loader, DEVICE)\n",
    "test['label'] = predictions.argmax(-1).numpy()\n",
    "test[['image_id', 'label']].to_csv(OUTPUT_DIR + 'submission.csv', index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
